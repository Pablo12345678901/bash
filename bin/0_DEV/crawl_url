#!/usr/bin/env bash

source fonctions_personnelles

# Syntaxe
SYNTAXE="$(syntaxe_afficher_si_erreur "$(basename $0)" "-u URL" )"

# Contrôle des arguments
FLAG_OPTION_U= # non défini par défaut pr test après lecture des options
while getopts ':u:' OPTION # le résultat de getopts à chaque boucle est stocké dans $OPTION
do
    case $OPTION in
        u )     FLAG_OPTION_U=1
                URL="$OPTARG"
                # Test si url existe
                if [ $(url_test_si_existe -u "$URL" ) -eq 0 ]
                then
                    :
                else
                    STDERR_afficher_message "\nERREUR : L'url \"$URL\" n'existe pas ou est déviée.\n"
                    STDERR_afficher_message "$SYNTAXE"
                    exit 1
                fi
                ;;
        # Argument manquant
        \: )    STDERR_afficher_message "\nERREUR : Argument manquant pour l'option -$OPTARG.\n" # les ':'' signifie que la valeur de l'argument n'a pas été trouvée = argument manquant
                STDERR_afficher_message "$SYNTAXE"
                exit 2
                ;;
        # Option inconnue
        \? )    STDERR_afficher_message "ERREUR : Option inconnue : -$OPTARG\n"
                STDERR_afficher_message "$SYNTAXE"
                exit 3
                ;;
    esac
done
shift $(($OPTIND - 1)) # décalage en supprimant les options acquises

# Test si l'option F a été fourni (=test si flag défini)
if [ ! -z "$FLAG_OPTION_U" ]
then
    # Test si d'autres darguments = en trop (=test si $1 défini)
    if [ ! -z "$1" ]
    then
        STDERR_afficher_message "\nERREUR : argument(s) en trop : \"$*\".\n"
        STDERR_afficher_message "$SYNTAXE"
        exit 4 
    else
        :
    fi
else
    STDERR_afficher_message "\nERREUR : Vous devez fournir l'option -u avec son argument.\n"
    STDERR_afficher_message "$SYNTAXE"
    exit 5 
fi

# Suppression du slash final s'il y a
URL="${URL%/}" 
# Récupération du domaine depuis l'url
DOMAINE="$(domaine_depuis_url -u "$URL")"
REGEX_DEBUT_URL="http(s)?://(www\.)?"

# Gestion des fichiers output
LISTE_URL_A_CRAWLER=~/Desktop/$(basename $0)_LISTE_URL_A_CRAWLER.txt
echo "$URL" > "$LISTE_URL_A_CRAWLER" # création du fichier (ou suppression du contenu si exsitant)
LISTE_URL_DEJA_CRAWLEES=~/Desktop/$(basename $0)_LISTE_URL_DEJA_CRAWLEES.txt
echo -n "" > "$LISTE_URL_DEJA_CRAWLEES" # création du fichier (ou suppression du contenu si existant)

# Tant que le fichier des urls à crawler a une taille >0 -> crawl 
while [ -s "$LISTE_URL_A_CRAWLER" ]
do
    # Test si url courante est vide -> remise à vide à chaque boucle
    if [ ${#URL_COURANTE} -eq 0 ]
    then
        # Tant que l'url courante est vide
        # -> récupération de la première ligne du fichier des urls à crawler
        # Et contrôle que pas déjà crawler en contrôlant si elle fait partie du fichier des urls déjà crawlées.
        # Sinon passe à l'url suivante.
        while [ ${#URL_COURANTE} -eq 0 ]
        do
            # Test à chaque boucle si fichier vide (car suppression d'une ligne à chaque fois)
            if [ -s "$LISTE_URL_A_CRAWLER" ]
            then
                :
            else
                break 2
            fi
            # récupération d'une ligne du fichier des url à crawler
            URL_RECUPEREE="$(head -n 1 "$LISTE_URL_A_CRAWLER")"
            # Suppression de cette ligne
            # Copie du fichier sauf la première ligne dans un fichier temporaire puis remplacement du fichier initial par ce nouveau fichier
            tail -n +2 "$LISTE_URL_A_CRAWLER" > "$LISTE_URL_A_CRAWLER.tmp" && mv "$LISTE_URL_A_CRAWLER.tmp" "$LISTE_URL_A_CRAWLER"
            # Si l'url récupérée n'est pas déjà dans le fichier des urls crawlées alors je la conserve
            # Sinon je passe à la prochain url (étant donné que la première ligne du fichier a été supprimée)
            if [ $(grep -c -m 1 "$URL_RECUPEREE" "$LISTE_URL_DEJA_CRAWLEES") -eq 0 ]
            then
                URL_COURANTE="$URL_RECUPEREE"
            fi
        done
    else
        : # Url courante non vide
    fi
    
    echo -e "Url en cours de crawlage : \"$URL_COURANTE\""
    
    # Ajout des url au fichier
    while read URL_TROUVE_SUR_BASE_DOMAINE
    do
        # Contrôle l'url est déjà dans le fichier
        # grep Check si un match - puis s'arrête si oui et retourne 1 (test si déjà dans un des 2 fichiers d'output)
        if [ $(grep -c -m 1 "$URL_TROUVE_SUR_BASE_DOMAINE" "$LISTE_URL_A_CRAWLER") -eq 0 ] && [ $(grep -c -m 1 "$URL_TROUVE_SUR_BASE_DOMAINE" "$LISTE_URL_DEJA_CRAWLEES") -eq 0 ]
        then
            # Ajout dans le fichier d'output si dans aucun des 2 fichiers
            echo "$URL_TROUVE_SUR_BASE_DOMAINE" >> "$LISTE_URL_A_CRAWLER"
        fi
        # Crawl sur base de l'url courante
    done < <(liens_depuis_html_avec_remplacement_slash_par_domaine -u "$URL_COURANTE" \
    | xargs -n 1 url_retourne_si_existe -u \
    | grep -o -E "$REGEX_DEBUT_URL.*\..*" \
    | grep "$DOMAINE" \
    | sort -u )
    # Étapes et commentaires de la production des URL
    # grep -o : récupère que la partie qui match des url
    # grep $DOMAINE : récupère que les urls qui contiennent le domaine
    # puis tri
    
    # Noter l'url qui a étée crawlée ds un autre fichier
    echo "$URL_COURANTE" >> "$LISTE_URL_DEJA_CRAWLEES"
    URL_COURANTE="" # remise à vide de l'url courante
done

# Suppression fichier des url à crawler
rm -rf "$LISTE_URL_A_CRAWLER"

# Tri des url du fichier des urls déjà crawlées
cat "$LISTE_URL_DEJA_CRAWLEES" | sort -u > "$LISTE_URL_DEJA_CRAWLEES.tmp" && mv "$LISTE_URL_DEJA_CRAWLEES.tmp" "$LISTE_URL_DEJA_CRAWLEES"

# Demande si affichage du fichier avec less y/n
REPONSE_AFFICHAGE=""
QUESTION_AFFICHAGE="Souhaiteriez-vous afficher l'output stocké dans le fichier
\"$LISTE_URL_DEJA_CRAWLEES\"
avec less ? (YyOo/Nn) "
question_oui_non REPONSE_AFFICHAGE "$QUESTION_AFFICHAGE"
if [ "$REPONSE_AFFICHAGE" = "o" ]
then
    less "$LISTE_URL_DEJA_CRAWLEES"
else
    :
fi

# Demande si suppression du fichier y/n
REPONSE_SUPPRESSION=""
QUESTION_SUPPRESSION="Souhaiteriez-vous supprimer le fichier d'output
\"$LISTE_URL_DEJA_CRAWLEES\"
? (YyOo/Nn) "
question_oui_non REPONSE_SUPPRESSION "$QUESTION_SUPPRESSION"
if [ "$REPONSE_SUPPRESSION" = "o" ]
then
    rm -rf "$LISTE_URL_DEJA_CRAWLEES"
else
    :
fi
